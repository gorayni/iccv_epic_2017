{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import brightside as bs\n",
    "import numpy as np\n",
    "import ntcir\n",
    "import ntcir.IO as IO\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = IO.load_annotations(ntcir.filepaths)\n",
    "categories = IO.load_categories(ntcir.filepaths)\n",
    "sorted_users = ntcir.utils.sort(users)\n",
    "\n",
    "# Full day sequences\n",
    "num_frames_per_day = 2880\n",
    "sequences = ntcir.get_sequences(sorted_users, num_frames_per_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preparing training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = ntcir.read_split('training_split.txt')\n",
    "validation_set = ntcir.read_split('validation_split.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap = 2\n",
    "training_batches = list()\n",
    "for user_id, date in training_set:\n",
    "    batches = ntcir.get_batches([(user_id, date)],sequences, overlap=overlap)\n",
    "    training_batches.append(batches)\n",
    "    \n",
    "validation_batches = list()\n",
    "for user_id, date in validation_set:\n",
    "    batches = ntcir.get_batches([(user_id, date)],sequences, overlap=overlap)\n",
    "    validation_batches.append(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Forcing keras to use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from experiments.utils import HistoryLog\n",
    "from experiments.utils import generate_batch\n",
    "import experiments as exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Acc: 0.000556792881348, Validation Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "from experiments.utils import load_images_batch\n",
    "\n",
    "\n",
    "num_training_batches = 0\n",
    "for day_batches in training_batches:\n",
    "    num_training_batches += len(day_batches)\n",
    "    \n",
    "num_validation_batches = 0\n",
    "for day_batches in validation_batches:\n",
    "    num_validation_batches += len(day_batches)\n",
    "    \n",
    "training_batches = [[training_batches[0][0]]]\n",
    "validation_batches = [[validation_batches[0][0]]]\n",
    "\n",
    "for learning_rate in [0.00001, 0.0001, 0.00005, 0.000025, 0.000075]:\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range=40,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True)\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=0.000005, momentum=0.9, nesterov=True)\n",
    "    model = exp.filtered_vgg_16_plus_lstm('weights.VGG-16.best.hdf5')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    weights_filepath=\"weights.Filtered_VGG16+LSTM.lr_{lr:f}.{epoch:02d}.hdf5\"\n",
    "    batch_size = timestep = 10\n",
    "    num_classes=21\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    train_acc = list()\n",
    "    val_acc = list()\n",
    "    loss = list()\n",
    "    mask = np.ones((1,timestep, num_classes))\n",
    "    prev_values = np.zeros((1,timestep, num_classes))    \n",
    "    for epoch in np.arange(1):\n",
    "\n",
    "        epoch_train_acc = list()\n",
    "        epoch_val_acc = list()\n",
    "\n",
    "        np.random.shuffle(training_batches) \n",
    "        for day_batches in training_batches:\n",
    "            mask[:,-overlap:,:] = 1\n",
    "            prev_values[:,-overlap:,:] = 0\n",
    "            for batch in day_batches:\n",
    "                batch_x, batch_y = load_images_batch(train_datagen, users, batch)\n",
    "                batch_loss, batch_acc = model.train_on_batch([batch_x, mask, prev_values], [batch_y])\n",
    "                prediction = model.predict_on_batch([batch_x, mask, prev_values])\n",
    "\n",
    "                mask[:,-overlap:,:] = 0\n",
    "                prev_values[:,-overlap:,:] = prediction[:,-overlap:,:]            \n",
    "\n",
    "                epoch_train_acc.append(batch_acc)\n",
    "                loss.append(batch_loss)\n",
    "\n",
    "        for day_batches in validation_batches:\n",
    "            mask[:,-overlap:,:] = 1\n",
    "            prev_values[:,-overlap:,:] = 0\n",
    "            for batch in day_batches:\n",
    "                batch_x, batch_y = load_images_batch(val_datagen, users, batch)\n",
    "                batch_loss, batch_acc = model.test_on_batch([batch_x, mask, prev_values], [batch_y])\n",
    "                prediction = model.predict_on_batch([batch_x, mask, prev_values])\n",
    "\n",
    "                mask[:,-overlap:,:] = 0\n",
    "                prev_values[:,-overlap:,:] = prediction[:,-overlap:,:]            \n",
    "\n",
    "                epoch_val_acc.append(batch_acc)\n",
    "\n",
    "        epoch_train_acc = np.sum(epoch_train_acc)*batch_size/num_training_batches\n",
    "        epoch_val_acc = np.sum(epoch_val_acc)*batch_size/num_validation_batches\n",
    "        print 'Epoch: {}, Train Acc: {}, Validation Acc: {}'.format(epoch+1, epoch_train_acc, epoch_val_acc)\n",
    "\n",
    "        model.save(weights_filepath.format(lr=learning_rate,epoch=epoch+1))\n",
    "\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        val_acc.append(epoch_val_acc)\n",
    "\n",
    "    loss = np.asarray(loss)\n",
    "    train_acc = np.asarray(train_acc)\n",
    "    val_acc = np.asarray(val_acc)\n",
    "\n",
    "    np.savetxt('lstm.Filtered_VGG16+LSTM.lr_{}.acc.log'.format(learning_rate), np.vstack((train_acc, val_acc)).T, delimiter=\",\")\n",
    "    np.savetxt('lstm.Filtered_VGG16+LSTM.lr_{}.loss.log'.format(learning_rate), loss.T, delimiter=\",\")\n",
    "    K.clear_session()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
