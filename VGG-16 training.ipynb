{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# VGG-16 training for 21 Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Defining common Keras functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.8):\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "KTF.set_session(get_session())\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "def define_model(img_width = 224, img_height = 224):\n",
    "    base_model = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))    \n",
    "    # The only trainable layers are the Fully Convolutional\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(21, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "    return Model(input=base_model.input, output=x)\n",
    "\n",
    "def define_dropout_model(img_width = 224, img_height = 224):\n",
    "    base_model = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    x = base_model.output        \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1', W_constraint=maxnorm(3))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2', W_constraint=maxnorm(3))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(21, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "    return Model(input=base_model.input, output=x)\n",
    "\n",
    "class HistoryLog(Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.training = edict({'loss': []})\n",
    "        self.epoch = edict({'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []})\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):        \n",
    "        self.epoch.acc.append(logs.get('acc'))\n",
    "        self.epoch.loss.append(logs.get('loss'))\n",
    "        self.epoch.val_acc.append(logs.get('val_acc'))\n",
    "        self.epoch.val_loss.append(logs.get('val_loss'))\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.training.loss.append(logs.get('loss'))\n",
    "        \n",
    "    def log_training_loss(self, filepath):\n",
    "        training_loss = np.array(self.training.loss)\n",
    "        np.savetxt(filepath, training_loss, delimiter=\",\")\n",
    "        \n",
    "    def log_epoch(self, filepath):\n",
    "        epoch = np.asarray([self.epoch.loss, self.epoch.val_loss, self.epoch.acc, self.epoch.val_acc])\n",
    "        np.savetxt(filepath, epoch.T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Printing VGG-16 adjusted architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           fc2[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 21)            86037       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,346,581\n",
      "Trainable params: 134,346,581\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_dropout_model()\n",
    "model.summary()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makedirs(dir_path):\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(dir_path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def num_digits(number):\n",
    "    return int(np.floor(np.log10(np.abs(number))) + 1)\n",
    "\n",
    "def ext(path):\n",
    "    return os.path.splitext(path)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def link_images(num_categories, split_dir, padding_zeros, targets, img_paths, indices=None):\n",
    "    counter_inst = np.ones((num_categories), np.int)\n",
    "    if indices == None:\n",
    "        indices = xrange(len(targets))\n",
    "        \n",
    "    for j in indices:\n",
    "        category_ind = targets[j]\n",
    "        img_dir = os.path.join(split_dir, str(category_ind))\n",
    "        \n",
    "        num_img = counter_inst[category_ind]\n",
    "        dst_basename = str(num_img).zfill(padding_zeros)\n",
    "        dst_basename += ext(img_paths[j])\n",
    "        dst_filepath = os.path.join(img_dir, dst_basename)\n",
    "\n",
    "        os.symlink(img_paths[j], dst_filepath)\n",
    "        counter_inst[category_ind] += 1\n",
    "\n",
    "def read_split(filepath):\n",
    "    days = list()\n",
    "    with open(filepath) as f:\n",
    "        for line in f.readlines():\n",
    "            user_id, date = line.replace(\"\\n\", \"\").split(' ')\n",
    "            days.append((user_id, date))\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_categories = len(categories)\n",
    "num_images = sum([u.num_images for u in users])\n",
    "padding_zeros = num_digits(num_images)\n",
    "\n",
    "splits = ['training','test','validation']\n",
    "filepaths = ['training_split.txt','validation_split.txt', 'test_split.txt']\n",
    "for split, filepath in zip(splits, filepaths):\n",
    "    \n",
    "    split_dir = osp.join('data', split)\n",
    "    if os.path.isdir(split_dir):\n",
    "        shutil.rmtree(split_dir)    \n",
    "    \n",
    "    for j in xrange(num_categories): \n",
    "        category = str(j)\n",
    "        category_dir = os.path.join(split_dir, category)\n",
    "        makedirs(category_dir)\n",
    "        \n",
    "    targets = list()\n",
    "    img_paths = list()\n",
    "    for user_id, date in read_split(filepath):\n",
    "        for image in days[user_id][date].images:\n",
    "            targets.append(image.label)\n",
    "            img_paths.append(image.path)\n",
    "    \n",
    "    link_images(num_categories, split_dir, padding_zeros, targets, img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
